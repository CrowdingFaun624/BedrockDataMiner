import json
from pathlib import Path
from typing import Any, Iterable, Sequence

import Dataminer.DataminerEnvironment as DataminerEnvironment
import Domain.Domain as Domain
import Structure.Container as Con
import Structure.DataPath as DataPath
import Structure.StructureBase as StructureBase
import Structure.StructureEnvironment as StructureEnvironment
import Structure.StructureInfo as StructureInfo
import Structure.StructureTag as StructureTag
import Utilities.Exceptions as Exceptions
import Utilities.File as File
import Utilities.Trace as Trace
import Version.Version as Version


class AbstractDataminerCollection():

    def __init__(self, file_name:str, name:str, domain:"Domain.Domain", comparing_disabled:bool) -> None:
        self.name = name
        self.file_name = file_name
        self.domain = domain
        self.comparing_disabled = comparing_disabled

    def link_subcomponents(self, structure:StructureBase.StructureBase) -> None:
        self.structure:StructureBase.StructureBase = structure

    def datamine(self, version:Version.Version, environment:DataminerEnvironment.DataminerEnvironment) -> Any: ...

    def store(self, version:Version.Version, environment:DataminerEnvironment.DataminerEnvironment) -> Any:
        '''Makes the DataminerCollection get the file. Returns the output and stores it in a file.'''
        data = self.datamine(version, environment)
        if data is None or data is ...:
            raise Exceptions.DataminerNullReturnError(self)
        version.data_directory.mkdir(exist_ok=True)
        with open(self.get_data_file_path(version), "wt") as f:
            json.dump(data, f, separators=(",", ":"), cls=self.domain.json_encoder)

        printer_environment = environment.get_printer_environment(version, self.get_structure_info(version))
        self.structure.type_check_from_raw(data, version, printer_environment)

        return self.get_data_file(version) # since the normalizing immediately before may modify it.

    def get_dependencies(self, version:Version.Version) -> Iterable["AbstractDataminerCollection"]: ...

    def get_data_file(self, version:Version.Version, non_exist_ok:bool=False) -> Any:
        '''Opens the data file if it exists, and raises an error if it doesn't, or returns None if `non_exist_ok` is True'''
        data_path = version.data_directory.joinpath(self.file_name)
        if not data_path.exists():
            if non_exist_ok:
                return None
            else:
                raise Exceptions.MissingDataFileError(self, self.file_name, version)
        with open(data_path, "rt") as f:
            return json.load(f, cls=self.domain.json_decoder)

    def remove_data_file(self, version:Version.Version) -> None:
        data_path = version.data_directory.joinpath(self.file_name)
        if data_path.exists():
            data_path.unlink()

    def has_tag(self, tag:StructureTag.StructureTag) -> bool:
        '''
        Returns True if the given tag could potentially be in this Version.
        :tag: The tag to test for.
        '''
        return self.structure.has_tag(tag)

    def get_tag_paths_from_raw(self, data:Any, version:Version.Version, tags:list[StructureTag.StructureTag], environment:StructureEnvironment.PrinterEnvironment) -> dict[StructureTag.StructureTag,Sequence[DataPath.DataPath]]:
        if not self.supports_version(version):
            return {tag: () for tag in tags}
        return self.structure.get_tag_paths_from_raw(data, tags, version, environment)

    def get_tag_paths_from_containerized(self, data:Con.Con, version:Version.Version, tags:list[StructureTag.StructureTag], environment:StructureEnvironment.PrinterEnvironment) -> dict[StructureTag.StructureTag,Sequence[DataPath.DataPath]]:
        if not self.supports_version(version):
            return {tag: () for tag in tags}
        return self.structure.get_tag_paths_from_containerized(data, tags, version, environment)

    def print_initial(self, version:Version.Version, environment:StructureEnvironment.StructureEnvironment, *, store:bool=True) -> str:
        version_data = self.get_data_file(version)
        structure_info = self.get_structure_info(version)
        report = self.structure.initial_report(version_data, version, structure_info, environment)
        if store:
            self.structure.store(report, self.name)
        return report

    def compare(
        self,
        version1:Version.Version,
        version2:Version.Version,
        versions_between:list[Version.Version],
        environment:StructureEnvironment.StructureEnvironment,
        *,
        store:bool=True,
    ) -> str:
        '''Stores the comparison generated by this DataminerCollection's Structure between two Versions, and returns the report.
        `data_cache` stores the output of `get_data_file`.'''
        version1_data = self.get_data_file(version1)
        version2_data = self.get_data_file(version2)
        structure_info1 = self.get_structure_info(version1)
        structure_info2 = self.get_structure_info(version2)
        report, had_changes = self.structure.comparison_report_two(version1_data, version2_data, version1, version2, structure_info1, structure_info2, versions_between, environment)
        if store and had_changes:
            self.structure.store(report, self.name)
        return report

    def get_structure_info(self, version:Version.Version) -> StructureInfo.StructureInfo:
        ...

    def check_types(self, version:Version.Version, environment:StructureEnvironment.PrinterEnvironment) -> None:
        if not self.supports_version(version):
            return
        data = self.get_data_file(version)
        self.structure.type_check_from_raw(data, version, environment)

    def __hash__(self) -> int:
        return hash(self.name)

    def __repr__(self) -> str:
        return f"<{self.__class__.__name__} {self.name}>"

    def clear_all_caches(self) -> None:
        '''Clears all caches of this DataminerCollection's Structure.'''
        self.structure.clear_all_caches()

    def clear_old_caches(self) -> None:
        '''Clears items from caches of this DataminerCollection's Structure and all of its children that are too old.'''
        self.structure.clear_old_caches()

    def supports_version(self, version:Version.Version) -> bool:
        return True

    def get_data_file_path(self, version:Version.Version) -> Path:
        return version.data_directory.joinpath(self.file_name)

    def get_referenced_files(self, version:Version.Version, structure_tags:dict[str,StructureTag.StructureTag], referenced_files:set[int]) -> None:
        structure_environment = StructureEnvironment.StructureEnvironment(StructureEnvironment.EnvironmentType.garbage_collection, self.domain)
        data_file = self.get_data_file(version, non_exist_ok=True)
        if data_file is None: return
        structure = self.structure
        file_tags = [structure_tag for structure_tag in structure_tags.values() if structure_tag.is_file]
        if structure.children_has_garbage_collection or structure.has_tags(file_tags):
            structure_info = self.get_structure_info(version)
            environment = StructureEnvironment.PrinterEnvironment(structure_environment, structure_info, None, version, 0)
            containerized_data = structure.get_containerized_from_raw(data_file, version, environment)
            trace = Trace.Trace()
            structure.get_referenced_files(containerized_data, trace, environment) # this is necessary just in case files appear only after normalization
            structure.print_exception_list(trace, (version,))
            for file_tag, paths in self.get_tag_paths_from_containerized(containerized_data, version, file_tags, environment).items(): # this is necessary just in case files are referenced only by a hash that isn't used.
                for data_path in paths:
                    match data_path.embedded_data:
                        case str():
                            referenced_files.add(File.hash_str_to_int(data_path.embedded_data))
                        case int():
                            referenced_files.add(data_path.embedded_data)
                        case _:
                            raise Exceptions.InvalidFileHashType(version, file_tag, data_path)
