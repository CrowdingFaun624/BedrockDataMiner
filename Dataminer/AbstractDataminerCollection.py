import json
from pathlib import Path
from types import EllipsisType
from typing import Any, Container, Iterable, Sequence

from ordered_set import OrderedSet

import Domain.Domain as Domain
import Utilities.Exceptions as Exceptions
from Dataminer.DataminerEnvironment import DataminerEnvironment
from Structure.Container import Con
from Structure.DataPath import DataPath
from Structure.StructureBase import StructureBase
from Structure.StructureEnvironment import (
    EnvironmentType,
    PrinterEnvironment,
    StructureEnvironment,
)
from Structure.StructureInfo import StructureInfo
from Structure.StructureTag import StructureTag
from Structure.Uses import UsageTracker, Use
from Utilities.Exceptions import InvalidStateError
from Utilities.File import hash_str_to_int
from Utilities.Trace import Trace
from Version.Version import Version


class AbstractDataminerCollection():

    __slots__ = (
        "comparing_disabled",
        "domain",
        "file_name",
        "full_name",
        "name",
        "structure",
    )

    def __init__(self, file_name:str, name:str, full_name:str, domain:"Domain.Domain", comparing_disabled:bool) -> None:
        self.name = name
        self.file_name = file_name
        self.full_name = full_name
        self.domain = domain
        self.comparing_disabled = comparing_disabled

    def link_subcomponents(self, structure:StructureBase) -> None:
        self.structure:StructureBase = structure

    def datamine(self, version:Version, environment:DataminerEnvironment) -> Any: ...

    def store(self, version:Version, environment:DataminerEnvironment) -> Any:
        '''Makes the DataminerCollection get the file. Returns the output and stores it in a file.'''
        data = self.datamine(version, environment)
        if data is None or data is ...:
            raise Exceptions.DataminerNullReturnError(self)
        version.data_directory.mkdir(exist_ok=True)
        with open(self.get_data_file_path(version), "wt") as f:
            json.dump(data, f, separators=(",", ":"), cls=self.domain.json_encoder)

        printer_environment = environment.get_printer_environment(version, self.get_structure_info(version))
        self.structure.type_check_from_raw(data, version, printer_environment)

        return self.get_data_file(version) # since the normalizing immediately before may modify it.

    def get_dependencies(self, version:Version) -> Iterable["AbstractDataminerCollection"]: ...

    def get_data_file(self, version:Version, non_exist_ok:bool=False) -> Any:
        '''Opens the data file if it exists, and raises an error if it doesn't, or returns None if `non_exist_ok` is True'''
        data_path = version.data_directory.joinpath(self.file_name)
        if not data_path.exists():
            if non_exist_ok:
                return None
            else:
                raise Exceptions.MissingDataFileError(self, self.file_name, version)
        with open(data_path, "rt") as f:
            return json.load(f, cls=self.domain.json_decoder)

    def remove_data_file(self, version:Version) -> None:
        data_path = version.data_directory.joinpath(self.file_name)
        if data_path.exists():
            data_path.unlink()

    def has_tag(self, tag:StructureTag) -> bool:
        '''
        Returns True if the given tag could potentially be in this Version.
        :tag: The tag to test for.
        '''
        return self.structure.has_tag(tag)

    def get_tag_paths_from_raw(self, data:Any, version:Version, tags:list[StructureTag], environment:PrinterEnvironment) -> dict[StructureTag,Sequence[DataPath]]:
        if not self.supports_version(version):
            return {tag: () for tag in tags}
        return self.structure.get_tag_paths_from_raw(data, tags, version, environment)

    def get_tag_paths_from_containerized(self, data:Con, version:Version, tags:list[StructureTag], environment:PrinterEnvironment) -> dict[StructureTag,Sequence[DataPath]]:
        if not self.supports_version(version):
            return {tag: () for tag in tags}
        return self.structure.get_tag_paths_from_containerized(data, tags, version, environment)

    def print_initial(self, version:Version, environment:StructureEnvironment, *, store:bool=True) -> str:
        version_data = self.get_data_file(version)
        structure_info = self.get_structure_info(version)
        report = self.structure.initial_report(version_data, version, structure_info, environment)
        if store:
            self.structure.store(report, self.name)
        return report

    def compare(
        self,
        version1:Version,
        version2:Version,
        versions_between:list[Version],
        environment:StructureEnvironment,
        *,
        store:bool=True,
    ) -> str:
        '''Stores the comparison generated by this DataminerCollection's Structure between two Versions, and returns the report.
        `data_cache` stores the output of `get_data_file`.'''
        version1_data = self.get_data_file(version1)
        version2_data = self.get_data_file(version2)
        structure_info1 = self.get_structure_info(version1)
        structure_info2 = self.get_structure_info(version2)
        report, had_changes = self.structure.comparison_report_two(version1_data, version2_data, version1, version2, structure_info1, structure_info2, versions_between, environment)
        if store and had_changes:
            self.structure.store(report, self.name)
        return report

    def get_structure_info(self, version:Version) -> StructureInfo:
        ...

    def check_types(self, version:Version, environment:PrinterEnvironment) -> None:
        if not self.supports_version(version):
            return
        data = self.get_data_file(version)
        self.structure.type_check_from_raw(data, version, environment)

    def __hash__(self) -> int:
        return hash(self.full_name)

    def __repr__(self) -> str:
        return f"<{self.__class__.__name__} {self.full_name}>"

    def clear_all_caches(self) -> None:
        '''Clears all caches of this DataminerCollection's Structure.'''
        self.structure.clear_all_caches()

    def clear_old_caches(self, structure_infos:Container[StructureInfo]) -> None:
        '''Clears items from caches of this DataminerCollection's Structure and all of its children that are too old.'''
        self.structure.clear_old_caches(structure_infos)

    def supports_version(self, version:Version) -> bool:
        return True

    def get_data_file_path(self, version:Version) -> Path:
        return version.data_directory.joinpath(self.file_name)

    def get_uses(self, version:Version, usage_tracker:UsageTracker) -> OrderedSet[Use]:
        data_file = self.get_data_file(version, non_exist_ok=True)
        if data_file is None:
            return OrderedSet(())
        structure_info = self.get_structure_info(version)
        structure_environment = StructureEnvironment(EnvironmentType.uses, self.domain)
        environment = PrinterEnvironment(structure_environment, structure_info, None, version, 0)
        containerized_data = self.structure.get_containerized_from_raw(data_file, version, environment)
        trace = Trace()
        output = self.structure.get_uses(containerized_data, usage_tracker, trace, environment)
        self.structure.ensure_not_ellipsis(None, trace, (version,))
        return output

    def get_all_uses(self) -> OrderedSet[Use]:
        return self.structure.get_all_uses(set())

    def get_referenced_files(self, version:Version, structure_tags:dict[str,StructureTag], referenced_files:set[int]) -> None:
        structure_environment = StructureEnvironment(EnvironmentType.garbage_collection, self.domain)
        file_tags = [structure_tag for structure_tag in structure_tags.values() if structure_tag.is_file]
        structure = self.structure
        if not structure.children_has_garbage_collection and not structure.has_tags(file_tags):
            return
        data_file = self.get_data_file(version, non_exist_ok=True)
        if data_file is None or not self.supports_version(version): # sometimes data_file may exist but the Version is still unsupported.
            return

        normalized_data:Any|EllipsisType = ...
        structure_info = self.get_structure_info(version)
        environment = PrinterEnvironment(structure_environment, structure_info, None, version, 0)
        trace = Trace()

        if structure.children_has_garbage_collection:
            normalized_data = structure.normalize_from_raw(data_file, trace, environment)
            structure.print_exception_list(trace, (version,))

        if structure.has_tags(file_tags):
            if normalized_data is ...:
                normalized_data = structure.normalize_from_raw(data_file, trace, environment)
            containerized_data = structure.containerize(normalized_data, trace, environment)
            structure.print_exception_list(trace, (version,))
            if containerized_data is ...: raise InvalidStateError()
            for file_tag, paths in self.get_tag_paths_from_containerized(containerized_data, version, file_tags, environment).items(): # this is necessary just in case files are referenced only by a hash that isn't used.
                for data_path in paths:
                    match data_path.embedded_data:
                        case str():
                            referenced_files.add(hash_str_to_int(data_path.embedded_data))
                        case int():
                            referenced_files.add(data_path.embedded_data)
                        case _:
                            raise Exceptions.InvalidFileHashType(version, file_tag, data_path)
            structure.print_exception_list(trace, (version,))
